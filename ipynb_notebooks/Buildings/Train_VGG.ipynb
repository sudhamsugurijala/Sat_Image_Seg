{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "hispanic-montgomery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Header Files\n",
    "import io\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "#from tqdm import tqdm \n",
    "\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, BatchNormalization, Activation\n",
    "from keras.layers.core import Dropout, Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras import backend as K\n",
    "#from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "working-profile",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.5)\n",
    "config=tf.compat.v1.ConfigProto(gpu_options=gpu_options)\n",
    "config.log_device_placement = False  # to log device placement (on which device the operation ran)\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "tf.compat.v1.keras.backend.set_session(sess)  # set this TensorFlow session as the default session for Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "clear-helping",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path Variables\n",
    "INPUT_H5 = \"data_images.h5\"\n",
    "MASKS_H5 = \"data_masks.h5\"\n",
    "MODEL_H5 = \"building_weights_VGG16.h5\"\n",
    "MODEL_FINAL = \"building_weights_VGG16_FINAL.h5\"\n",
    "\n",
    "# Size Variables\n",
    "\n",
    "IMG_SIZE = (256,256)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "SEED = 303"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "polyphonic-minute",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIOU(y_true, y_pred, smooth=1):\n",
    "  tf.cast(y_true, tf.float32)\n",
    "  tf.cast(y_pred, tf.float32)\n",
    "  intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n",
    "  union = K.sum(y_true,[1,2,3])+K.sum(y_pred,[1,2,3])-intersection\n",
    "  return K.mean((intersection + smooth) / (union + smooth), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "alpha-afghanistan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280741\n",
      "280741\n"
     ]
    }
   ],
   "source": [
    "hf1 = h5py.File(INPUT_H5, 'r')\n",
    "hf2 = h5py.File(MASKS_H5,'r')\n",
    "\n",
    "input_image=[]\n",
    "input_mask=[]\n",
    "\n",
    "input_image = list(hf1.keys())\n",
    "input_image = sorted(input_image)\n",
    "#print(input_image)\n",
    "\n",
    "input_mask = list(hf2.keys())\n",
    "input_mask  = sorted(input_mask)\n",
    "#print(input_mask)\n",
    "\n",
    "print(len(input_image))\n",
    "print(len(input_mask))\n",
    "\n",
    "hf1.close()\n",
    "hf2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "wireless-attendance",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_samples = 28074\n",
    "random.Random(1337).shuffle(input_image)\n",
    "random.Random(1337).shuffle(input_mask)\n",
    "\n",
    "train_input_img_paths  =  input_image[:-val_samples]\n",
    "train_target_img_paths =  input_mask[:-val_samples]\n",
    "val_input_img_paths    =  input_image[-val_samples:]\n",
    "val_target_img_paths   =  input_mask[-val_samples:]\n",
    "\n",
    "train_input_img_paths=sorted(train_input_img_paths)\n",
    "train_target_img_paths=sorted(train_target_img_paths)\n",
    "val_input_img_paths=sorted(val_input_img_paths)\n",
    "val_target_img_paths=sorted(val_target_img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sixth-demand",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7895\n",
      "877\n"
     ]
    }
   ],
   "source": [
    "class DataLoad(keras.utils.Sequence):\n",
    "    \"\"\"Helper to iterate over the data (as Numpy arrays).\"\"\"\n",
    "\n",
    "    def __init__(self, batch_size, img_size, input_img_paths, target_img_paths):\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.input_img_paths = input_img_paths\n",
    "        self.target_img_paths = target_img_paths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target_img_paths) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Returns tuple (input, target) correspond to batch #idx.\"\"\"\n",
    "        i = idx * self.batch_size\n",
    "        batch_input_img_paths = self.input_img_paths[i : i + self.batch_size]\n",
    "        batch_target_img_paths = self.target_img_paths[i : i + self.batch_size]\n",
    "        x= np.zeros((self.batch_size, 256,256,3), dtype=np.uint8)\n",
    "        for j, path in enumerate(batch_input_img_paths):\n",
    "            h5 = h5py.File(INPUT_H5, 'r')\n",
    "            data=h5.get(path)\n",
    "            data=np.array(data)\n",
    "            img = Image.open(io.BytesIO(data))\n",
    "            img=np.array(img)\n",
    "            img=resize(img, (256,256), mode='constant',  preserve_range=True)\n",
    "            x[j] = img\n",
    "        \n",
    "        y=np.zeros((self.batch_size, 256, 256, 1), dtype=np.bool)\n",
    "        for j, path in enumerate(batch_target_img_paths):\n",
    "            mask = np.zeros((256,256, 1), dtype=np.bool)\n",
    "            h51=h5py.File(MASKS_H5,'r')\n",
    "            data=h51.get(path)\n",
    "            data=np.array(data)\n",
    "            mask_=Image.open(io.BytesIO(data))\n",
    "            \n",
    "            mask_=np.array(mask_)\n",
    "            mask_ = np.expand_dims(resize(mask_, (256,256), mode='constant',preserve_range=True), axis=-1)\n",
    "            mask = np.maximum(mask, mask_) \n",
    "            y[j]=mask\n",
    "            \n",
    "           \n",
    "        return x, y\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_gen = DataLoad(BATCH_SIZE, IMG_SIZE, train_input_img_paths, train_target_img_paths)\n",
    "val_gen = DataLoad(BATCH_SIZE, IMG_SIZE, val_input_img_paths, val_target_img_paths)\n",
    "\n",
    "print(len(train_gen))\n",
    "print(len(val_gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "compact-journal",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH=256\n",
    "IMG_HEIGHT=256\n",
    "IMG_CHANNELS=3\n",
    "\n",
    "NUM_CLASSES = 1\n",
    "OPTIMIZER = 'adam'\n",
    "\n",
    "#BUILD THE U-NET MODEL\n",
    "def conv_block(tensor, nfilters, size=3, padding='same', initializer=\"he_normal\"):\n",
    "    x = Conv2D(filters=nfilters, kernel_size=(size, size), padding=padding, kernel_initializer=initializer)(tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Conv2D(filters=nfilters, kernel_size=(size, size), padding=padding, kernel_initializer=initializer)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def deconv_block(tensor, residual, nfilters, size=3, padding='same', strides=(2, 2)):\n",
    "    y = Conv2DTranspose(nfilters, kernel_size=(size, size), strides=strides, padding=padding)(tensor)\n",
    "    y = concatenate([y, residual], axis=3)\n",
    "    y = conv_block(y, nfilters)\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "complicated-anger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.engine.training.Model object at 0x7f56d84c1c88>\n",
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 256, 256, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "vgg = tf.keras.applications.VGG16(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_shape=(256, 256, 3),\n",
    "        pooling=max\n",
    "    )\n",
    "print(vgg)\n",
    "print(vgg.summary())\n",
    "\n",
    "vgg.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "familiar-trinity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGG(img_height=IMG_HEIGHT, img_width=IMG_WIDTH, nclasses=NUM_CLASSES, filters=64):\n",
    "    input_layer = vgg.input\n",
    "    \n",
    "    # Contraction path\n",
    "   \n",
    "\n",
    "    s1 = vgg.get_layer(\"block1_conv2\").output         # 64 filters\n",
    "    s2 = vgg.get_layer(\"block2_conv2\").output         # 128 filters\n",
    "    s3 = vgg.get_layer(\"block3_conv3\").output         # 256 filters\n",
    "    s4 = vgg.get_layer(\"block4_conv3\").output         # 512 filters\n",
    "\n",
    "    # Bridge \n",
    "    b1 = vgg.get_layer(\"block5_conv3\").output  # 512   \n",
    "    #b1 = Dropout(0.5)(b1)\n",
    "    # Expansion Path\n",
    "    d1 = deconv_block(b1, s4, nfilters=filters*8)  \n",
    "    #d1 = Dropout(0.3)(d1)                   \n",
    "    d2 = deconv_block(d1, s3, nfilters=filters*4)   \n",
    "    #d2 = Dropout(0.5)(d2)                 \n",
    "    d3 = deconv_block(d2, s2, nfilters=filters*2)                     \n",
    "    d4 = deconv_block(d3, s1, nfilters=filters)                      \n",
    "    \n",
    "    # Output\n",
    "    \n",
    "    output_layer = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n",
    "    #output_layer = Conv2D(filters=NUM_CLASSES, kernel_size=(1, 1))(d4)\n",
    "    #output_layer = BatchNormalization()(output_layer)\n",
    "    #output_layer = Activation('sigmoid')(output_layer)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer, name='VGG16')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "english-share",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(patience=4, monitor='loss'),\n",
    "        tf.keras.callbacks.TensorBoard(log_dir='logs'),\n",
    "        tf.keras.callbacks.ModelCheckpoint(MODEL_H5, verbose=1, save_best_only=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "small-recorder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"VGG16\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 256, 256, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 256, 256, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 128, 128, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 128, 128, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 128, 128, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 64, 64, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 64, 64, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 64, 64, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 64, 64, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 32, 32, 256)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 32, 32, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 32, 32, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 32, 32, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 16, 16, 512)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 16, 16, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 16, 16, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 16, 16, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 32, 32, 512)  2359808     block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 32, 32, 1024) 0           conv2d_transpose[0][0]           \n",
      "                                                                 block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 32, 32, 512)  4719104     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 32, 32, 512)  2048        conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 32, 32, 512)  0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 512)  2359808     activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 512)  2048        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 512)  0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 64, 64, 256)  1179904     activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 64, 64, 512)  0           conv2d_transpose_1[0][0]         \n",
      "                                                                 block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 64, 64, 256)  1179904     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 64, 64, 256)  1024        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 64, 64, 256)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 64, 64, 256)  590080      activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 64, 64, 256)  1024        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 64, 64, 256)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 128, 128, 128 295040      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 128, 128, 256 0           conv2d_transpose_2[0][0]         \n",
      "                                                                 block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 128, 128, 128 295040      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 128, 128, 128 512         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 128, 128, 128 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 128, 128, 128 147584      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 128, 128, 128 512         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 128, 128, 128 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 256, 256, 64) 73792       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 256, 256, 128 0           conv2d_transpose_3[0][0]         \n",
      "                                                                 block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 256, 256, 64) 73792       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 256, 256, 64) 256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 256, 256, 64) 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 256, 256, 64) 36928       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 256, 256, 64) 256         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 256, 256, 64) 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 256, 256, 1)  65          activation_7[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 28,033,217\n",
      "Trainable params: 13,314,689\n",
      "Non-trainable params: 14,718,528\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#model = uNet()\n",
    "model = VGG()\n",
    "model.summary()\n",
    "\n",
    "# Compile if any of above fresh models are used\n",
    "model.compile(optimizer=OPTIMIZER, loss='binary_crossentropy', metrics=['accuracy',getIOU])\n",
    "\n",
    "#model = load_model(\"resnet_adam_50epochs.h5\")\n",
    "\n",
    "# Uncomment line below when fine tuning\n",
    "#model.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "polar-spyware",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7895/7895 [==============================] - ETA: 0s - loss: 0.1745 - accuracy: 0.9275 - getIOU: 0.6760\n",
      "Epoch 00001: val_loss improved from inf to 0.15564, saving model to building_weights_VGG16.h5\n",
      "7895/7895 [==============================] - 3691s 468ms/step - loss: 0.1745 - accuracy: 0.9275 - getIOU: 0.6760 - val_loss: 0.1556 - val_accuracy: 0.9362 - val_getIOU: 0.7163\n",
      "Epoch 2/10\n",
      "7895/7895 [==============================] - ETA: 0s - loss: 0.1387 - accuracy: 0.9424 - getIOU: 0.7299\n",
      "Epoch 00002: val_loss improved from 0.15564 to 0.13133, saving model to building_weights_VGG16.h5\n",
      "7895/7895 [==============================] - 3670s 465ms/step - loss: 0.1387 - accuracy: 0.9424 - getIOU: 0.7299 - val_loss: 0.1313 - val_accuracy: 0.9452 - val_getIOU: 0.7355\n",
      "Epoch 3/10\n",
      "7895/7895 [==============================] - ETA: 0s - loss: 0.1239 - accuracy: 0.9480 - getIOU: 0.7546\n",
      "Epoch 00003: val_loss improved from 0.13133 to 0.12074, saving model to building_weights_VGG16.h5\n",
      "7895/7895 [==============================] - 3662s 464ms/step - loss: 0.1239 - accuracy: 0.9480 - getIOU: 0.7546 - val_loss: 0.1207 - val_accuracy: 0.9494 - val_getIOU: 0.7546\n",
      "Epoch 4/10\n",
      "7895/7895 [==============================] - ETA: 0s - loss: 0.1143 - accuracy: 0.9518 - getIOU: 0.7721\n",
      "Epoch 00004: val_loss improved from 0.12074 to 0.11719, saving model to building_weights_VGG16.h5\n",
      "7895/7895 [==============================] - 3501s 443ms/step - loss: 0.1143 - accuracy: 0.9518 - getIOU: 0.7721 - val_loss: 0.1172 - val_accuracy: 0.9507 - val_getIOU: 0.7731\n",
      "Epoch 5/10\n",
      "7895/7895 [==============================] - ETA: 0s - loss: 0.1076 - accuracy: 0.9544 - getIOU: 0.7846\n",
      "Epoch 00005: val_loss improved from 0.11719 to 0.10973, saving model to building_weights_VGG16.h5\n",
      "7895/7895 [==============================] - 3498s 443ms/step - loss: 0.1076 - accuracy: 0.9544 - getIOU: 0.7846 - val_loss: 0.1097 - val_accuracy: 0.9538 - val_getIOU: 0.7871\n",
      "Epoch 6/10\n",
      "7895/7895 [==============================] - ETA: 0s - loss: 0.1022 - accuracy: 0.9566 - getIOU: 0.7950\n",
      "Epoch 00006: val_loss improved from 0.10973 to 0.10545, saving model to building_weights_VGG16.h5\n",
      "7895/7895 [==============================] - 3499s 443ms/step - loss: 0.1022 - accuracy: 0.9566 - getIOU: 0.7950 - val_loss: 0.1055 - val_accuracy: 0.9556 - val_getIOU: 0.7868\n",
      "Epoch 7/10\n",
      "7895/7895 [==============================] - ETA: 0s - loss: 0.0977 - accuracy: 0.9584 - getIOU: 0.8035\n",
      "Epoch 00007: val_loss improved from 0.10545 to 0.10244, saving model to building_weights_VGG16.h5\n",
      "7895/7895 [==============================] - 3504s 444ms/step - loss: 0.0977 - accuracy: 0.9584 - getIOU: 0.8035 - val_loss: 0.1024 - val_accuracy: 0.9569 - val_getIOU: 0.7973\n",
      "Epoch 8/10\n",
      "7895/7895 [==============================] - ETA: 0s - loss: 0.0939 - accuracy: 0.9599 - getIOU: 0.8108\n",
      "Epoch 00008: val_loss improved from 0.10244 to 0.09943, saving model to building_weights_VGG16.h5\n",
      "7895/7895 [==============================] - 3494s 443ms/step - loss: 0.0939 - accuracy: 0.9599 - getIOU: 0.8108 - val_loss: 0.0994 - val_accuracy: 0.9581 - val_getIOU: 0.8014\n",
      "Epoch 9/10\n",
      "7895/7895 [==============================] - ETA: 0s - loss: 0.0906 - accuracy: 0.9613 - getIOU: 0.8173\n",
      "Epoch 00009: val_loss improved from 0.09943 to 0.09708, saving model to building_weights_VGG16.h5\n",
      "7895/7895 [==============================] - 3495s 443ms/step - loss: 0.0906 - accuracy: 0.9613 - getIOU: 0.8173 - val_loss: 0.0971 - val_accuracy: 0.9592 - val_getIOU: 0.8054\n",
      "Epoch 10/10\n",
      "7895/7895 [==============================] - ETA: 0s - loss: 0.0877 - accuracy: 0.9626 - getIOU: 0.8231\n",
      "Epoch 00010: val_loss improved from 0.09708 to 0.09458, saving model to building_weights_VGG16.h5\n",
      "7895/7895 [==============================] - 3496s 443ms/step - loss: 0.0877 - accuracy: 0.9626 - getIOU: 0.8231 - val_loss: 0.0946 - val_accuracy: 0.9604 - val_getIOU: 0.8163\n",
      "<tensorflow.python.keras.callbacks.History object at 0x7f56d824c7f0>\n",
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "results = model.fit(train_gen,epochs=EPOCHS,batch_size=BATCH_SIZE, validation_data=val_gen,callbacks=callbacks)\n",
    "print(results)\n",
    "\n",
    "model.save(MODEL_FINAL)\n",
    "print(\"Model Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brilliant-batch",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "satelliteFYP",
   "language": "python",
   "name": "satellitefyp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
